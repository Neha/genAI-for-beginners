This is the 2nd blog from the series  - "[Learning GenAI](https://dev.to/hellonehha/genai-for-dummies-48j7)". 

In today's blog we are going to learn about LLMs (Large Language Model). 

## Large Language Models (LLMs)

LLMs, or "Large Language Models," are advanced AI models that are pre-trained on vast amounts of text data to perform a variety of language-related tasks. These models serve as the backbone of Generative AI, enabling machines to understand and generate human-like text.

While developing a GenAI application, we need to decide which LLM to use. There are different LLMs provider, and pricing is also differ.

## Workflow of LLMs:

The basic workflow of an LLM can be summarized as:

Input (from user) → Context Window → LLM → Output

**Let’s break down each step:**

a. **Input**: The initial input provided by the user. This could be a question, a prompt, or any text that the user wants the AI to process.

b. **Context Window**: This is the portion of the input (and sometimes previous interactions) that the LLM considers when generating a response. The context window has a fixed size, meaning it can only hold a certain number of tokens (words or characters).

c. **LLM**: The Large Language Model processes the information within the context window, using its vast training to understand and generate a relevant response.

d. **Output**: The response generated by the LLM based on the provided context.

## Types of LLMs:

There are different ways to use LLMs depending on your needs:

1. **Use Pre-trained LLMs**: Utilize models that have already been trained on large datasets by AI providers. These models are ready to use and can be implemented directly into applications.

2. **Train Your Own Models**: If you have specific requirements, you can train your own models using custom data to better suit your use case.

3. **Hybrid Approach**: Combine pre-trained models with custom-trained models to leverage the benefits of both general knowledge and specialized training.

## Foundational Models

Foundational models are pre-trained LLMs provided by various AI providers. They are a great starting point for building applications:

1. **Pre-Trained Models:** These are ready-to-use models available through different providers.

2. **APIs and SDKs:** Foundational models often come with APIs and SDKs, making it easier to integrate them into your projects.

3. **Application Development:** You can use a foundational model’s API to build applications on top of it, utilizing the pre-trained capabilities for your specific needs.

## How to Choose a Foundational Model

When selecting a foundational model, consider the following factors:

1. **Use Cases**: Choose a model that aligns with the specific tasks or applications you want to develop.

2. **Pricing**: Evaluate the cost associated with using the model, especially if your application requires extensive usage.

3. **Token Limits**: Be aware of the context window size and the number of tokens a model can process, as this can affect performance.

## Common Foundational Models

Here are some popular foundational models used in the industry:

1. **GPT**: Developed by OpenAI, known for generating high-quality text.

2. **BERT**: Created by Google, excels in understanding the context of words in search queries.

3. **T5**: A text-to-text transfer transformer that can perform multiple NLP tasks.

4. **Claude**: A model by Anthropic, designed for safe and effective conversational AI.

5. **Jurassic**: Developed by AI21, known for its large-scale natural language processing capabilities.

Happy Learning!!